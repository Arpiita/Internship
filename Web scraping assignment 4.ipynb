{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c570483",
   "metadata": {},
   "source": [
    "# Question 1.\n",
    "Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87ef53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "from time import sleep\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0984b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edc927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cd2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing data after scraping\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d6d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "#scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "    \n",
    "    \n",
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "    \n",
    "    \n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "# Scraping Views of videos\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75053785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.83  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.02  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.54  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.86  \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   5.81  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.71  \n",
       "6                                       ChuChu TV      March 6, 2014   5.04  \n",
       "7                                     Mark Ronson  November 19, 2014   4.77  \n",
       "8                                     Miroshka TV  February 27, 2018   4.74  \n",
       "9                      Cocomelon – Nursery Rhymes       May 24, 2018   4.69  \n",
       "10                                            Psy      July 15, 2012   4.62  \n",
       "11                                     Get Movies   January 31, 2012   4.52  \n",
       "12                                      El Chombo      April 5, 2018   4.15  \n",
       "13                                       Maroon 5   January 14, 2015   3.79  \n",
       "14                                     Katy Perry  September 5, 2013   3.69  \n",
       "15                                    OneRepublic       May 31, 2013   3.69  \n",
       "16                                     Crazy Frog      June 16, 2009   3.63  \n",
       "17                                  Justin Bieber   October 22, 2015   3.61  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.52  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.44  \n",
       "20                                     Katy Perry  February 20, 2014   3.40  \n",
       "21                                    Alan Walker   December 3, 2015   3.38  \n",
       "22                                       Maroon 5       May 31, 2018   3.35  \n",
       "23                                      Passenger      July 25, 2012   3.35  \n",
       "24                                        Shakira       June 4, 2010   3.34  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.31  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.30  \n",
       "27                                    Major Lazer     March 22, 2015   3.29  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.24  \n",
       "29                                   Taylor Swift    August 18, 2014   3.23  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "wikipedia = pd.DataFrame({})\n",
    "wikipedia['Rank']=Rank\n",
    "wikipedia['Name']=Name\n",
    "wikipedia['Artist']=Artist\n",
    "wikipedia['Upload Date']=UploadDate\n",
    "wikipedia['Views']=Views\n",
    "\n",
    "wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4739780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95068b77",
   "metadata": {},
   "source": [
    "# Question 2.\n",
    "Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4ef803ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1d73f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9cfcd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickin on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bb611f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA T20 SERIES 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA T20 SERIES 2022-23']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = []\n",
    "series_tag = driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in series_tag:\n",
    "    series.append(i.text)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c892efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd T20I',\n",
       " '1st Test',\n",
       " '3rd T20I',\n",
       " '4th T20I',\n",
       " '5th T20I',\n",
       " '2nd Test',\n",
       " '1st T20I',\n",
       " '2nd T20I']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping match title\n",
    "title = []\n",
    "title_tag = driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title_tag:\n",
    "    title.append(i.text.split(' -')[0])\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3cb27d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' DY Patil Stadium, NAVI MUMBAI',\n",
       " ' Zahur Ahmed Chowdhury Stadium, Chattogram',\n",
       " ' Brabourne',\n",
       " ' Brabourne',\n",
       " ' Brabourne',\n",
       " ' Shere Bangla National Stadium, Mirpur, Dhaka',\n",
       " ' Wankhede Stadium, Mumbai',\n",
       " ' Maharashtra Cricket Association Stadium, Pune']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Place\n",
    "place = []\n",
    "place_tag = driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in place_tag:\n",
    "    place.append(i.text.split(' -')[1])\n",
    "place "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "56f3bcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '17 DEC 2022',\n",
       " '20 DEC 2022',\n",
       " '22 DEC 2022',\n",
       " '3 JAN 2023',\n",
       " '5 JAN 2023']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Date\n",
    "date = []\n",
    "date_tag = driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for i in date_tag:\n",
    "    date.append(i.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c6100236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = []\n",
    "time_tag = driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "for i in time_tag:\n",
    "    time.append(i.text)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "352f73de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium, Chattogram</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>17 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>20 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>22 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                                        Series  \\\n",
       "0    2nd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "1    1st Test  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "2    3rd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "3    4th T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "4    5th T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "5    2nd Test  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "6    1st T20I    SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "7    2nd T20I    SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "\n",
       "                                            Place         Date         Time  \n",
       "0                   DY Patil Stadium, NAVI MUMBAI  11 DEC 2022  7:00 PM IST  \n",
       "1       Zahur Ahmed Chowdhury Stadium, Chattogram  14 DEC 2022  9:30 AM IST  \n",
       "2                                       Brabourne  14 DEC 2022  7:00 PM IST  \n",
       "3                                       Brabourne  17 DEC 2022  7:00 PM IST  \n",
       "4                                       Brabourne  20 DEC 2022  7:00 PM IST  \n",
       "5    Shere Bangla National Stadium, Mirpur, Dhaka  22 DEC 2022  9:30 AM IST  \n",
       "6                        Wankhede Stadium, Mumbai   3 JAN 2023  7:30 PM IST  \n",
       "7   Maharashtra Cricket Association Stadium, Pune   5 JAN 2023  7:30 PM IST  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "df = pd.DataFrame({'Match Title':title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ca91c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca557a3e",
   "metadata": {},
   "source": [
    "# Question3.\n",
    "Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "-  A) Name\n",
    "-  B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "af106022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4f78ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(' https://www.guru99.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ccb03dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on selenium exception handling  Button\n",
    "exception_handling = driver.find_element(By.XPATH,\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "try:\n",
    "    exception_handling.click()\n",
    "except ElementNotInteractableException:  #if the above code doesn't work/is not clickable then, the below code will handle it\n",
    "    driver.get(exception_handling.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2504ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "#scraping names\n",
    "name = driver.find_elements(By.XPATH,\"/html/body/div[1]/div/div/div/main/div/article/div/div/p/strong\")\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "\n",
    "# scraping Description\n",
    "desc = driver.find_elements(By.XPATH,\"/html/body/div[1]/div/div/div/main/div/article/div/div/p\")\n",
    "for i in desc:       \n",
    "        if i.text is None :\n",
    "            Description.append(\"--\")\n",
    "        else:\n",
    "            Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bda192cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. ElementNotVisibleException:',\n",
       " '2. ElementNotSelectableException:',\n",
       " '3. NoSuchElementException:',\n",
       " '4. NoSuchFrameException:',\n",
       " '5. NoAlertPresentException:',\n",
       " '6. NoSuchWindowException:',\n",
       " '7. StaleElementReferenceException:',\n",
       " '8. SessionNotFoundException:',\n",
       " '9. TimeoutException:',\n",
       " '10. WebDriverException:',\n",
       " '11. ConnectionClosedException:',\n",
       " '12. ElementClickInterceptedException:',\n",
       " '13. ElementNotInteractableException:',\n",
       " '14. ErrorInResponseException:',\n",
       " '15. ErrorHandler.UnknownServerException:',\n",
       " '16. ImeActivationFailedException:',\n",
       " '17. ImeNotAvailableException:',\n",
       " '18. InsecureCertificateException:',\n",
       " '19. InvalidArgumentException:',\n",
       " '20. InvalidCookieDomainException:',\n",
       " '21. InvalidCoordinatesException:',\n",
       " '22. InvalidElementStateException:',\n",
       " '23. InvalidSessionIdException:',\n",
       " '24. InvalidSwitchToTargetException:',\n",
       " '25. JavascriptException:',\n",
       " '26. JsonException:',\n",
       " '27. NoSuchAttributeException:',\n",
       " '28. MoveTargetOutOfBoundsException:',\n",
       " '29. NoSuchContextException:',\n",
       " '30. NoSuchCookieException:',\n",
       " '31. NotFoundException:',\n",
       " '32. RemoteDriverServerException:',\n",
       " '33. ScreenshotException:',\n",
       " '34. SessionNotCreatedException:',\n",
       " '35. UnableToSetCookieException:',\n",
       " '36. UnexpectedTagNameException:',\n",
       " '37. UnhandledAlertException:',\n",
       " '38. UnexpectedAlertPresentException:',\n",
       " '39. UnknownMethodException:',\n",
       " '40. UnreachableBrowserException:',\n",
       " '41. UnsupportedCommandException:',\n",
       " 'Step 1) Try-catch',\n",
       " 'Catch',\n",
       " 'Step 2) Multiple catch blocks',\n",
       " 'Step 3) Throw',\n",
       " 'Step 4) Multiple Exceptions',\n",
       " 'Step 5) Finally']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bf9c19aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. ElementNotVisibleException: This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       " '2. ElementNotSelectableException: This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       " '3. NoSuchElementException: This Exception occurs if an element could not be found.',\n",
       " '4. NoSuchFrameException: This Exception occurs if the frame target to be switched to does not exist.',\n",
       " '5. NoAlertPresentException: This Exception occurs when you switch to no presented alert.',\n",
       " '6. NoSuchWindowException: This Exception occurs if the window target to be switch does not exist.',\n",
       " '7. StaleElementReferenceException: This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       " '8. SessionNotFoundException: The WebDriver is acting after you quit the browser.',\n",
       " '9. TimeoutException: Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn’t found in the specified time.',\n",
       " '10. WebDriverException: This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       " '11. ConnectionClosedException: This type of Exception takes place when there is a disconnection in the driver.',\n",
       " '12. ElementClickInterceptedException: The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       " '13. ElementNotInteractableException: This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       " '14. ErrorInResponseException: This happens while interacting with the Firefox extension or the remote driver server.',\n",
       " '15. ErrorHandler.UnknownServerException: Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       " '16. ImeActivationFailedException: This expectation will occur when IME engine activation has failed.',\n",
       " '17. ImeNotAvailableException: It takes place when IME support is unavailable.',\n",
       " '18. InsecureCertificateException: Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       " '19. InvalidArgumentException: It occurs when an argument does not belong to the expected type.',\n",
       " '20. InvalidCookieDomainException: This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       " '21. InvalidCoordinatesException: This type of Exception matches an interacting operation that is not valid.',\n",
       " '22. InvalidElementStateException: It occurs when command can’t be finished when the element is invalid.',\n",
       " '23. InvalidSessionIdException: This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       " '24. InvalidSwitchToTargetException: This occurs when the frame or window target to be switched does not exist.',\n",
       " '25. JavascriptException: This issue occurs while executing JavaScript given by the user.',\n",
       " '26. JsonException: It occurs when you afford to get the session when the session is not created.',\n",
       " '27. NoSuchAttributeException: This kind of Exception occurs when the attribute of an element could not be found.',\n",
       " '28. MoveTargetOutOfBoundsException: It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       " '29. NoSuchContextException: ContextAware does mobile device testing.',\n",
       " '30. NoSuchCookieException: This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       " '31. NotFoundException: This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       " '32. RemoteDriverServerException: This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       " '33. ScreenshotException: It is not possible to capture a screen.',\n",
       " '34. SessionNotCreatedException: It happens when a new session could not be successfully created.',\n",
       " '35. UnableToSetCookieException: This occurs if a driver is unable to set a cookie.',\n",
       " '36. UnexpectedTagNameException: Happens if a support class did not get a web element as expected.',\n",
       " '37. UnhandledAlertException: This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       " '38. UnexpectedAlertPresentException: It occurs when there is the appearance of an unexpected alert.',\n",
       " '39. UnknownMethodException: This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       " '40. UnreachableBrowserException: This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       " '41. UnsupportedCommandException: This occurs when remote WebDriver doesn’t send valid commands as expected.',\n",
       " 'Here, are some important standard using which you can handle Exceptions in Selenium WebDriver:',\n",
       " 'Step 1) Try-catch',\n",
       " 'This method can catch Exceptions, which uses a combination of the try and catch keywords. Try command indicates the start of the block, and Catch is placed at the end of the try block, which helps to resolve the Exception.',\n",
       " 'Step 2) Multiple catch blocks',\n",
       " 'There are various types of Exceptions, and you can expect more than one exception from a single block of code. Multiple catches help you to handle every type of Exception separately with a separate block of code. It can be used for more than two catch blocks, and there is no limitation on the number of catch blocks.',\n",
       " 'Step 3) Throw',\n",
       " 'When you want to generate an Exception, the Throw keyword is used to throw Exception to handle it in the run time. When you are throwing an Exception without handling it, then they need to use Throw keyword.',\n",
       " 'Step 4) Multiple Exceptions',\n",
       " 'You can mention various Exceptions in the throws clause.',\n",
       " 'Step 5) Finally',\n",
       " 'The Final keyword is used to create a block of code under the try block. It is the final code that helps you to executes irrespective of the occurrence of an exception',\n",
       " 'You can also use the following methods to display Exception Information:']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "46d81787",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2efe787",
   "metadata": {},
   "source": [
    "# Question 4.\n",
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "712de06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94988c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.statisticstimes.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea6533ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40050e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9a0501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on India button\n",
    "driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b286ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2cb9590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []\n",
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9bdd440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE      GSDP2   SHARE GDPbillion\n",
       "0     1                Maharashtra  2,632,792  13.94%    399.921\n",
       "1     2                 Tamil Nadu  1,630,208   8.63%    247.629\n",
       "2     3              Uttar Pradesh  1,584,764   8.39%    240.726\n",
       "3     4                    Gujarat  1,502,899   7.96%    228.290\n",
       "4     5                  Karnataka  1,493,127   7.91%    226.806\n",
       "..  ...                        ...        ...     ...        ...\n",
       "61   29                     Sikkim     25,141   0.15%     17,060\n",
       "62   30                   Nagaland     24,534   0.15%          -\n",
       "63   31          Arunachal Pradesh     22,488   0.13%          -\n",
       "64   32                    Mizoram     20,947   0.13%     17,797\n",
       "65   33  Andaman & Nicobar Islands          -       -          -\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank\n",
    "INDIA['STATE']=State\n",
    "INDIA['GSDP2']=GSDP2\n",
    "INDIA['SHARE']=Share\n",
    "INDIA['GDPbillion']=GDPbillion\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04c7773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf1760",
   "metadata": {},
   "source": [
    "# Question 5.\n",
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a66642fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "594e8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(' https://github.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "09955537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Open source\n",
    "\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "23dda05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on Trending\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "27d4efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list:\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "65badfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repository Title data\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1cb3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    \n",
    "        # Scraping Repository Description data\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,\"//p[@class='f4 my-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "     # Scraping Languages used data\n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e9064602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_title),len(Description),len(Contributors),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c761db56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>19</td>\n",
       "      <td>[TypeScript, Python, Dockerfile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>869413421 / wechatbot</td>\n",
       "      <td>为个人微信接入ChatGPT</td>\n",
       "      <td>3</td>\n",
       "      <td>[Go, Dockerfile, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exaloop / codon</td>\n",
       "      <td>A high-performance, zero-overhead, extensible ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[C++, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doocs / leetcode</td>\n",
       "      <td>😏 LeetCode solutions in any programming langua...</td>\n",
       "      <td>108</td>\n",
       "      <td>[Java, C++, Python, Go, TypeScript, Rust, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teaxyz / cli</td>\n",
       "      <td>the unified package manager (brew2)</td>\n",
       "      <td>17</td>\n",
       "      <td>[TypeScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tencent / Hippy</td>\n",
       "      <td>Hippy is designed to easily build cross-platfo...</td>\n",
       "      <td>80</td>\n",
       "      <td>[C++, Java, Objective-C, TypeScript, JavaScrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloneofsimo / lora</td>\n",
       "      <td>Using Low-rank adaptation to quickly fine-tune...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Jupyter Notebook, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>ChatGPT for wechat</td>\n",
       "      <td>2</td>\n",
       "      <td>[TypeScript, JavaScript, Dockerfile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PathOfBuildingCommunity / PathOfBuilding</td>\n",
       "      <td>Offline build planner for Path of Exile.</td>\n",
       "      <td>187</td>\n",
       "      <td>[Lua]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surrealdb / surrealdb</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>31</td>\n",
       "      <td>[Rust, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gragland / chatgpt-chrome-extension</td>\n",
       "      <td>A ChatGPT Chrome extension. Integrates ChatGPT...</td>\n",
       "      <td>-</td>\n",
       "      <td>[JavaScript, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wangrongding / wechat-bot</td>\n",
       "      <td>🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 可以用来帮助你...</td>\n",
       "      <td>2</td>\n",
       "      <td>[JavaScript, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mohammadpz / pytorch_forward_forward</td>\n",
       "      <td>Implementation of Hinton's forward-forward (FF...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>holbertonschool / Betty</td>\n",
       "      <td>Holberton-style C code checker written in Perl</td>\n",
       "      <td>8</td>\n",
       "      <td>[Perl, C, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>humanloop / awesome-chatgpt</td>\n",
       "      <td>Curated list of awesome tools, demos, docs for...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rawandahmad698 / PyChatGPT</td>\n",
       "      <td>⚡️ Python client for the unofficial ChatGPT AP...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pulsar-edit / pulsar</td>\n",
       "      <td>A Community-led Hyper-Hackable Text Editor</td>\n",
       "      <td>487</td>\n",
       "      <td>[JavaScript, CoffeeScript, Less, Ruby, Shell, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bupticybee / ChineseAiDungeonChatGPT</td>\n",
       "      <td>中文版的ai地牢，直接使用的openai的ChatGPT api作为讲故事的模型。</td>\n",
       "      <td>3</td>\n",
       "      <td>[Python, Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>This repo includes ChatGPT promt curation to u...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>louislam / uptime-kuma</td>\n",
       "      <td>A fancy self-hosted monitoring tool</td>\n",
       "      <td>209</td>\n",
       "      <td>[JavaScript, Vue, SCSS, TypeScript, Shell, Doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pichenettes / eurorack</td>\n",
       "      <td>Eurorack modules</td>\n",
       "      <td>11</td>\n",
       "      <td>[C++, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acheong08 / ChatGPT</td>\n",
       "      <td>Lightweight package for interacting with ChatG...</td>\n",
       "      <td>23</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>paradigmxyz / reth</td>\n",
       "      <td>Modular, contributor-friendly and blazing-fast...</td>\n",
       "      <td>13</td>\n",
       "      <td>[C, Rust, C++, CMake, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bytedance / sonic-cpp</td>\n",
       "      <td>A fast JSON serializing &amp; deserializing librar...</td>\n",
       "      <td>3</td>\n",
       "      <td>[C++, Python, CMake, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AmazingAng / WTF-Solidity</td>\n",
       "      <td>我最近在重新学solidity，巩固一下细节，也写一个“WTF Solidity极简入门”，...</td>\n",
       "      <td>70</td>\n",
       "      <td>[Solidity, JavaScript]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository title  \\\n",
       "0              fuergaosi233 / wechat-chatgpt   \n",
       "1                      869413421 / wechatbot   \n",
       "2                            exaloop / codon   \n",
       "3                           doocs / leetcode   \n",
       "4                               teaxyz / cli   \n",
       "5                            Tencent / Hippy   \n",
       "6                         cloneofsimo / lora   \n",
       "7             AutumnWhj / ChatGPT-wechat-bot   \n",
       "8   PathOfBuildingCommunity / PathOfBuilding   \n",
       "9                      surrealdb / surrealdb   \n",
       "10       gragland / chatgpt-chrome-extension   \n",
       "11                 wangrongding / wechat-bot   \n",
       "12      mohammadpz / pytorch_forward_forward   \n",
       "13                   holbertonschool / Betty   \n",
       "14               humanloop / awesome-chatgpt   \n",
       "15                rawandahmad698 / PyChatGPT   \n",
       "16                      pulsar-edit / pulsar   \n",
       "17      bupticybee / ChineseAiDungeonChatGPT   \n",
       "18               f / awesome-chatgpt-prompts   \n",
       "19                    louislam / uptime-kuma   \n",
       "20                    pichenettes / eurorack   \n",
       "21                       acheong08 / ChatGPT   \n",
       "22                        paradigmxyz / reth   \n",
       "23                     bytedance / sonic-cpp   \n",
       "24                 AmazingAng / WTF-Solidity   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0                   Use ChatGPT On Wechat via wechaty                 19   \n",
       "1                                      为个人微信接入ChatGPT                  3   \n",
       "2   A high-performance, zero-overhead, extensible ...                  4   \n",
       "3   😏 LeetCode solutions in any programming langua...                108   \n",
       "4                 the unified package manager (brew2)                 17   \n",
       "5   Hippy is designed to easily build cross-platfo...                 80   \n",
       "6   Using Low-rank adaptation to quickly fine-tune...                  2   \n",
       "7                                  ChatGPT for wechat                  2   \n",
       "8            Offline build planner for Path of Exile.                187   \n",
       "9   A scalable, distributed, collaborative, docume...                 31   \n",
       "10  A ChatGPT Chrome extension. Integrates ChatGPT...                  -   \n",
       "11  🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 可以用来帮助你...                  2   \n",
       "12  Implementation of Hinton's forward-forward (FF...                  2   \n",
       "13     Holberton-style C code checker written in Perl                  8   \n",
       "14  Curated list of awesome tools, demos, docs for...                  5   \n",
       "15  ⚡️ Python client for the unofficial ChatGPT AP...                  8   \n",
       "16         A Community-led Hyper-Hackable Text Editor                487   \n",
       "17          中文版的ai地牢，直接使用的openai的ChatGPT api作为讲故事的模型。                  3   \n",
       "18  This repo includes ChatGPT promt curation to u...                 10   \n",
       "19                A fancy self-hosted monitoring tool                209   \n",
       "20                                   Eurorack modules                 11   \n",
       "21  Lightweight package for interacting with ChatG...                 23   \n",
       "22  Modular, contributor-friendly and blazing-fast...                 13   \n",
       "23  A fast JSON serializing & deserializing librar...                  3   \n",
       "24  我最近在重新学solidity，巩固一下细节，也写一个“WTF Solidity极简入门”，...                 70   \n",
       "\n",
       "                                        Language used  \n",
       "0             [TypeScript, Python, Dockerfile, Shell]  \n",
       "1                          [Go, Dockerfile, Makefile]  \n",
       "2                                [C++, Python, Other]  \n",
       "3    [Java, C++, Python, Go, TypeScript, Rust, Other]  \n",
       "4                                        [TypeScript]  \n",
       "5   [C++, Java, Objective-C, TypeScript, JavaScrip...  \n",
       "6                           [Jupyter Notebook, Other]  \n",
       "7         [TypeScript, JavaScript, Dockerfile, Shell]  \n",
       "8                                               [Lua]  \n",
       "9                                       [Rust, Other]  \n",
       "10                                [JavaScript, Shell]  \n",
       "11                                [JavaScript, Shell]  \n",
       "12                                           [Python]  \n",
       "13                                   [Perl, C, Shell]  \n",
       "14                                                 []  \n",
       "15                                           [Python]  \n",
       "16  [JavaScript, CoffeeScript, Less, Ruby, Shell, ...  \n",
       "17                         [Python, Jupyter Notebook]  \n",
       "18                                                 []  \n",
       "19  [JavaScript, Vue, SCSS, TypeScript, Shell, Doc...  \n",
       "20                               [C++, Python, Other]  \n",
       "21                                           [Python]  \n",
       "22                       [C, Rust, C++, CMake, Other]  \n",
       "23                        [C++, Python, CMake, Other]  \n",
       "24                             [Solidity, JavaScript]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c055a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f7cad",
   "metadata": {},
   "source": [
    "# Question 6.\n",
    "Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "017074f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "47b0e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0ee395c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x005FF243]\n\t(No symbol) [0x00587FD1]\n\t(No symbol) [0x0047CF10]\n\t(No symbol) [0x004AD003]\n\t(No symbol) [0x004A32A6]\n\t(No symbol) [0x004C858C]\n\t(No symbol) [0x004A2BFF]\n\t(No symbol) [0x004C8804]\n\t(No symbol) [0x004DC9EB]\n\t(No symbol) [0x004C8386]\n\t(No symbol) [0x004A163C]\n\t(No symbol) [0x004A269D]\n\tGetHandleVerifier [0x00899A22+2655074]\n\tGetHandleVerifier [0x0088CA24+2601828]\n\tGetHandleVerifier [0x006A8C0A+619850]\n\tGetHandleVerifier [0x006A7830+614768]\n\t(No symbol) [0x005905FC]\n\t(No symbol) [0x00595968]\n\t(No symbol) [0x00595A55]\n\t(No symbol) [0x005A051B]\n\tBaseThreadInitThunk [0x7690FEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77687BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77687B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [196]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# clicking the chart\u001b[39;00m\n\u001b[0;32m      2\u001b[0m chart\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/div[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mchart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# clicking the view chart\u001b[39;00m\n\u001b[0;32m      6\u001b[0m hot100\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/main/div[2]/div/div[1]/a/div[2]/div[2]/div[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x005FF243]\n\t(No symbol) [0x00587FD1]\n\t(No symbol) [0x0047CF10]\n\t(No symbol) [0x004AD003]\n\t(No symbol) [0x004A32A6]\n\t(No symbol) [0x004C858C]\n\t(No symbol) [0x004A2BFF]\n\t(No symbol) [0x004C8804]\n\t(No symbol) [0x004DC9EB]\n\t(No symbol) [0x004C8386]\n\t(No symbol) [0x004A163C]\n\t(No symbol) [0x004A269D]\n\tGetHandleVerifier [0x00899A22+2655074]\n\tGetHandleVerifier [0x0088CA24+2601828]\n\tGetHandleVerifier [0x006A8C0A+619850]\n\tGetHandleVerifier [0x006A7830+614768]\n\t(No symbol) [0x005905FC]\n\t(No symbol) [0x00595968]\n\t(No symbol) [0x00595A55]\n\t(No symbol) [0x005A051B]\n\tBaseThreadInitThunk [0x7690FEF9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77687BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77687B8E+238]\n"
     ]
    }
   ],
   "source": [
    "# clicking the chart\n",
    "chart=driver.find_element(By.XPATH,\"/html/body/div[1]\")\n",
    "chart.click()\n",
    "\n",
    "# clicking the view chart\n",
    "hot100=driver.find_element(By.XPATH,\"/html/body/main/div[2]/div/div[1]/a/div[2]/div[2]/div[1]\")\n",
    "hot100.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "# scraping Song name\n",
    "song = driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in song:       \n",
    "    if i.text is None :\n",
    "        Song_name.append(\"--\") \n",
    "    else:\n",
    "        Song_name.append(i.text)         \n",
    "\n",
    "# scraping Artist name\n",
    "artist = driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:       \n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text) \n",
    "        \n",
    "# scraping last week rank\n",
    "lw_rank = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lw_rank:       \n",
    "    if i.text is None :\n",
    "        Last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        Last_week_rank.append(i.text)  \n",
    "\n",
    "# scraping peak rank\n",
    "peak = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:       \n",
    "    if i.text is None :\n",
    "        Peak_rank.append(\"--\") \n",
    "    else:\n",
    "        Peak_rank.append(i.text)    \n",
    "\n",
    "# scraping Weeks_on_board\n",
    "on_board = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in on_board:       \n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\")\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Song_name\":Song_name,\"Artist_name\":Artist_name,\"Last_week_rank\":Last_week_rank,\"Peak_rank\":Peak_rank,\"Weeks_on_board\":Weeks_on_board})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5be76",
   "metadata": {},
   "source": [
    "# Question 7.\n",
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a0dfb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "850caeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(' https://www.naukri.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "24e0d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching search button, sending keys and clicking on it\n",
    "search_field = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "search_field.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d3efffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f0000983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the title\n",
    "name = []\n",
    "name_tag = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)\n",
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "486f34d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the company name\n",
    "comp = []\n",
    "comp_tag = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    comp.append(i.text)\n",
    "len(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c8263b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping skills\n",
    "skill = []\n",
    "skill_tag = driver.find_elements(By.XPATH,'//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in skill_tag:\n",
    "    skill.append(i.text)\n",
    "len(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a79a8cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping location\n",
    "loc = []\n",
    "loc_tag = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    loc.append(i.text)\n",
    "len(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8443959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>BS / MS or PhD in a quantitative field - Appli...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Data Science</td>\n",
       "      <td>Bristlecone</td>\n",
       "      <td>Graduation Post Graduation in Statistics Compe...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Manager - Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Masters / PhDs in a quantitative field (Comput...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - Data Sciences</td>\n",
       "      <td>GEP</td>\n",
       "      <td>, code review and version control tools, batch...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>- We are looking for passionate and skilled da...</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>You will be required to utilize the existing f...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Skill required: Data Science - Python Programm...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Lead - Forecasting</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Bachelor s degree in Computer science, Statist...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>The ideal candidate should have a strong clien...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paytm - Data Science - Lead</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>Bachelor s degree in technical/ analytics/ dat...</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consultant - Data Science</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Qualitative skills: Should have played project...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>5+ years of experience in designing, developin...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Requirements: Responsible for taking up day-to...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science- Data Scientist/Sr. Data Scientist</td>\n",
       "      <td>Jet2 Travel Technologies</td>\n",
       "      <td>As a part of J2TT, the successful candidate wi...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deputy National Lead - Payments - Data Science</td>\n",
       "      <td>BAJAJ FINSERVE</td>\n",
       "      <td>Bachelor s Degree in computer science, Math, P...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Geeky Bee AI Pvt Ltd</td>\n",
       "      <td>We are looking for Data Science Engineers with...</td>\n",
       "      <td>Pune(Wakad)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Ira Commerce</td>\n",
       "      <td>Experience in Developing and enhancing algorit...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manager / Senior Manager - Data Science</td>\n",
       "      <td>PYLON Management Consulting Private Limited</td>\n",
       "      <td>Nice to have: Phd or degree from IIT / IIM/oth...</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Analyst - Applied Data Science</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>finance or digital preferred 4 years Experienc...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manager, Data Science 1</td>\n",
       "      <td>Paypal</td>\n",
       "      <td>Bachelor s / Master s degree in a quantitative...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            JOB Title  \\\n",
       "0                                Analyst-Data Science   \n",
       "1                       Data Scientist - Data Science   \n",
       "2                          Sr. Manager - Data Science   \n",
       "3                 Lead Data Scientist - Data Sciences   \n",
       "4                  Data Science - Engineering Manager   \n",
       "5                                Analyst-Data Science   \n",
       "6                         Senior Analyst-Data Science   \n",
       "7                     Data Science Lead - Forecasting   \n",
       "8   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "9                         Paytm - Data Science - Lead   \n",
       "10                          Consultant - Data Science   \n",
       "11                       Senior Data Science Engineer   \n",
       "12  ACN - Applied Intelligence - CC - Data Science...   \n",
       "13    Data Science- Data Scientist/Sr. Data Scientist   \n",
       "14     Deputy National Lead - Payments - Data Science   \n",
       "15                              Data Science Engineer   \n",
       "16                               Data Science Analyst   \n",
       "17            Manager / Senior Manager - Data Science   \n",
       "18              Senior Analyst - Applied Data Science   \n",
       "19                            Manager, Data Science 1   \n",
       "\n",
       "                                        Company  \\\n",
       "0                              AMERICAN EXPRESS   \n",
       "1                                   Bristlecone   \n",
       "2                              AMERICAN EXPRESS   \n",
       "3                                           GEP   \n",
       "4                                         Paytm   \n",
       "5                                     Accenture   \n",
       "6                                     Accenture   \n",
       "7                                       Cargill   \n",
       "8                                     Accenture   \n",
       "9                                         Paytm   \n",
       "10                             Affine Analytics   \n",
       "11                                      Bizongo   \n",
       "12                                    Accenture   \n",
       "13                     Jet2 Travel Technologies   \n",
       "14                               BAJAJ FINSERVE   \n",
       "15                         Geeky Bee AI Pvt Ltd   \n",
       "16                                 Ira Commerce   \n",
       "17  PYLON Management Consulting Private Limited   \n",
       "18                                        Tesco   \n",
       "19                                       Paypal   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   BS / MS or PhD in a quantitative field - Appli...   \n",
       "1   Graduation Post Graduation in Statistics Compe...   \n",
       "2   Masters / PhDs in a quantitative field (Comput...   \n",
       "3   , code review and version control tools, batch...   \n",
       "4   - We are looking for passionate and skilled da...   \n",
       "5   You will be required to utilize the existing f...   \n",
       "6   Skill required: Data Science - Python Programm...   \n",
       "7   Bachelor s degree in Computer science, Statist...   \n",
       "8   The ideal candidate should have a strong clien...   \n",
       "9   Bachelor s degree in technical/ analytics/ dat...   \n",
       "10  Qualitative skills: Should have played project...   \n",
       "11  5+ years of experience in designing, developin...   \n",
       "12  Requirements: Responsible for taking up day-to...   \n",
       "13  As a part of J2TT, the successful candidate wi...   \n",
       "14  Bachelor s Degree in computer science, Math, P...   \n",
       "15  We are looking for Data Science Engineers with...   \n",
       "16  Experience in Developing and enhancing algorit...   \n",
       "17  Nice to have: Phd or degree from IIT / IIM/oth...   \n",
       "18  finance or digital preferred 4 years Experienc...   \n",
       "19  Bachelor s / Master s degree in a quantitative...   \n",
       "\n",
       "                                       Location  \n",
       "0                              Gurgaon/Gurugram  \n",
       "1                                        Mumbai  \n",
       "2                              Gurgaon/Gurugram  \n",
       "3                                        Remote  \n",
       "4                New Delhi, Bangalore/Bengaluru  \n",
       "5                           Bangalore/Bengaluru  \n",
       "6                                        Mumbai  \n",
       "7                           Bangalore/Bengaluru  \n",
       "8                           Bangalore/Bengaluru  \n",
       "9            Noida, Mumbai, Bangalore/Bengaluru  \n",
       "10                          Bangalore/Bengaluru  \n",
       "11                  Mumbai, Bangalore/Bengaluru  \n",
       "12                             Gurgaon/Gurugram  \n",
       "13                                         Pune  \n",
       "14                                         Pune  \n",
       "15                                  Pune(Wakad)  \n",
       "16                       Hyderabad/Secunderabad  \n",
       "17  Pune, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "18                          Bangalore/Bengaluru  \n",
       "19                                      Chennai  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame of scraped data\n",
    "df = pd.DataFrame({'JOB Title':name,'Company':comp,'Skills':skill,'Location':loc})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "87aa3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0363d44",
   "metadata": {},
   "source": [
    "# Question 8.\n",
    ". Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0d59e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "af7ca0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ac588af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Da Vinci Code,The',\n",
       " 'Brown, Dan',\n",
       " '5,094,805',\n",
       " 'Transworld',\n",
       " '2',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Rowling, J.K.',\n",
       " '4,475,152',\n",
       " 'Bloomsbury',\n",
       " '3',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Rowling, J.K.',\n",
       " '4,200,654',\n",
       " 'Bloomsbury',\n",
       " '4',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Rowling, J.K.',\n",
       " '4,179,479',\n",
       " 'Bloomsbury',\n",
       " '5',\n",
       " 'Fifty Shades of Grey',\n",
       " 'James, E. L.',\n",
       " '3,758,936',\n",
       " 'Random House',\n",
       " '6',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Rowling, J.K.',\n",
       " '3,583,215',\n",
       " 'Bloomsbury',\n",
       " '7',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Rowling, J.K.',\n",
       " '3,484,047',\n",
       " 'Bloomsbury',\n",
       " '8',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Rowling, J.K.',\n",
       " '3,377,906',\n",
       " 'Bloomsbury',\n",
       " '9',\n",
       " 'Angels and Demons',\n",
       " 'Brown, Dan',\n",
       " '3,193,946',\n",
       " 'Transworld',\n",
       " '10',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Rowling, J.K.',\n",
       " '2,950,264',\n",
       " 'Bloomsbury',\n",
       " '11',\n",
       " 'Fifty Shades Darker',\n",
       " 'James, E. L.',\n",
       " '2,479,784',\n",
       " 'Random House',\n",
       " '12',\n",
       " 'Twilight',\n",
       " 'Meyer, Stephenie',\n",
       " '2,315,405',\n",
       " 'Little, Brown Book',\n",
       " '13',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '2,233,570',\n",
       " 'Quercus',\n",
       " '14',\n",
       " 'Fifty Shades Freed',\n",
       " 'James, E. L.',\n",
       " '2,193,928',\n",
       " 'Random House',\n",
       " '15',\n",
       " 'Lost Symbol,The',\n",
       " 'Brown, Dan',\n",
       " '2,183,031',\n",
       " 'Transworld',\n",
       " '16',\n",
       " 'New Moon',\n",
       " 'Meyer, Stephenie',\n",
       " '2,152,737',\n",
       " 'Little, Brown Book',\n",
       " '17',\n",
       " 'Deception Point',\n",
       " 'Brown, Dan',\n",
       " '2,062,145',\n",
       " 'Transworld',\n",
       " '18',\n",
       " 'Eclipse',\n",
       " 'Meyer, Stephenie',\n",
       " '2,052,876',\n",
       " 'Little, Brown Book',\n",
       " '19',\n",
       " 'Lovely Bones,The',\n",
       " 'Sebold, Alice',\n",
       " '2,005,598',\n",
       " 'Pan Macmillan',\n",
       " '20',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Haddon, Mark',\n",
       " '1,979,552',\n",
       " 'Random House',\n",
       " '21',\n",
       " 'Digital Fortress',\n",
       " 'Brown, Dan',\n",
       " '1,928,900',\n",
       " 'Transworld',\n",
       " '22',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Bryson, Bill',\n",
       " '1,852,919',\n",
       " 'Transworld',\n",
       " '23',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '1,814,784',\n",
       " 'Quercus',\n",
       " '24',\n",
       " 'Breaking Dawn',\n",
       " 'Meyer, Stephenie',\n",
       " '1,787,118',\n",
       " 'Little, Brown Book',\n",
       " '25',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Carle, Eric',\n",
       " '1,783,535',\n",
       " 'Penguin',\n",
       " '26',\n",
       " 'Gruffalo,The',\n",
       " 'Donaldson, Julia',\n",
       " '1,781,269',\n",
       " 'Pan Macmillan',\n",
       " '27',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Oliver, Jamie',\n",
       " '1,743,266',\n",
       " 'Penguin',\n",
       " '28',\n",
       " 'Kite Runner,The',\n",
       " 'Hosseini, Khaled',\n",
       " '1,629,119',\n",
       " 'Bloomsbury',\n",
       " '29',\n",
       " 'One Day',\n",
       " 'Nicholls, David',\n",
       " '1,616,068',\n",
       " 'Hodder & Stoughton',\n",
       " '30',\n",
       " 'Thousand Splendid Suns,A',\n",
       " 'Hosseini, Khaled',\n",
       " '1,583,992',\n",
       " 'Bloomsbury',\n",
       " '31',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " 'Larsson, Stieg',\n",
       " '1,555,135',\n",
       " 'Quercus',\n",
       " '32',\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Niffenegger, Audrey',\n",
       " '1,546,886',\n",
       " 'Random House',\n",
       " '33',\n",
       " 'Atonement',\n",
       " 'McEwan, Ian',\n",
       " '1,539,428',\n",
       " 'Random House',\n",
       " '34',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'Fielding, Helen',\n",
       " '1,508,205',\n",
       " 'Pan Macmillan',\n",
       " '35',\n",
       " 'World According to Clarkson,The',\n",
       " 'Clarkson, Jeremy',\n",
       " '1,489,403',\n",
       " 'Penguin',\n",
       " '36',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Bernieres, Louis de',\n",
       " '1,352,318',\n",
       " 'Random House',\n",
       " '37',\n",
       " 'Sound of Laughter,The',\n",
       " 'Kay, Peter',\n",
       " '1,310,207',\n",
       " 'Random House',\n",
       " '38',\n",
       " 'Life of Pi',\n",
       " 'Martel, Yann',\n",
       " '1,310,176',\n",
       " 'Canongate',\n",
       " '39',\n",
       " 'Billy Connolly',\n",
       " 'Stephenson, Pamela',\n",
       " '1,231,957',\n",
       " 'HarperCollins',\n",
       " '40',\n",
       " 'Child Called It,A',\n",
       " 'Pelzer, Dave',\n",
       " '1,217,712',\n",
       " 'Orion',\n",
       " '41',\n",
       " \"Gruffalo's Child,The\",\n",
       " 'Donaldson, Julia',\n",
       " '1,208,711',\n",
       " 'Pan Macmillan',\n",
       " '42',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'McCourt, Frank',\n",
       " '1,204,058',\n",
       " 'HarperCollins',\n",
       " '43',\n",
       " 'Birdsong',\n",
       " 'Faulks, Sebastian',\n",
       " '1,184,967',\n",
       " 'Random House',\n",
       " '44',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,181,503',\n",
       " 'Scholastic Ltd.',\n",
       " '45',\n",
       " 'Labyrinth',\n",
       " 'Mosse, Kate',\n",
       " '1,181,093',\n",
       " 'Orion',\n",
       " '46',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Rowling, J.K.',\n",
       " '1,153,181',\n",
       " 'Bloomsbury',\n",
       " '47',\n",
       " 'Help,The',\n",
       " 'Stockett, Kathryn',\n",
       " '1,132,336',\n",
       " 'Penguin',\n",
       " '48',\n",
       " 'Man and Boy',\n",
       " 'Parsons, Tony',\n",
       " '1,130,802',\n",
       " 'HarperCollins',\n",
       " '49',\n",
       " 'Memoirs of a Geisha',\n",
       " 'Golden, Arthur',\n",
       " '1,126,337',\n",
       " 'Random House',\n",
       " '50',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'McCall Smith, Alexander',\n",
       " '1,115,549',\n",
       " 'Little, Brown Book',\n",
       " '51',\n",
       " 'Island,The',\n",
       " 'Hislop, Victoria',\n",
       " '1,108,328',\n",
       " 'Headline',\n",
       " '52',\n",
       " 'PS, I Love You',\n",
       " 'Ahern, Cecelia',\n",
       " '1,107,379',\n",
       " 'HarperCollins',\n",
       " '53',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'McKeith, Gillian',\n",
       " '1,104,403',\n",
       " 'Penguin',\n",
       " '54',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " '1,092,349',\n",
       " 'Orion',\n",
       " '55',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Rowling, J.K.',\n",
       " '1,090,847',\n",
       " 'Bloomsbury',\n",
       " '56',\n",
       " 'Broker,The',\n",
       " 'Grisham, John',\n",
       " '1,087,262',\n",
       " 'Random House',\n",
       " '57',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Atkins, Robert C.',\n",
       " '1,054,196',\n",
       " 'Random House',\n",
       " '58',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,037,160',\n",
       " 'Scholastic Ltd.',\n",
       " '59',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " 'Truss, Lynne',\n",
       " '1,023,688',\n",
       " 'Profile Books Group',\n",
       " '60',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Smith, Delia',\n",
       " '1,015,956',\n",
       " 'Random House',\n",
       " '61',\n",
       " 'Chocolat',\n",
       " 'Harris, Joanne',\n",
       " '1,009,873',\n",
       " 'Transworld',\n",
       " '62',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Boyne, John',\n",
       " '1,004,414',\n",
       " 'Random House Childrens Books G',\n",
       " '63',\n",
       " \"My Sister's Keeper\",\n",
       " 'Picoult, Jodi',\n",
       " '1,003,780',\n",
       " 'Hodder & Stoughton',\n",
       " '64',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,002,314',\n",
       " 'Scholastic Ltd.',\n",
       " '65',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Lee, Harper',\n",
       " '998,213',\n",
       " 'Random House',\n",
       " '66',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Gray, John',\n",
       " '992,846',\n",
       " 'HarperCollins',\n",
       " '67',\n",
       " 'Dear Fatty',\n",
       " 'French, Dawn',\n",
       " '986,753',\n",
       " 'Random House',\n",
       " '68',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lewycka, Marina',\n",
       " '986,115',\n",
       " 'Penguin',\n",
       " '69',\n",
       " 'Hannibal',\n",
       " 'Harris, Thomas',\n",
       " '970,509',\n",
       " 'Random House',\n",
       " '70',\n",
       " 'Lord of the Rings,The',\n",
       " 'Tolkien, J. R. R.',\n",
       " '967,466',\n",
       " 'HarperCollins',\n",
       " '71',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Moore, Michael',\n",
       " '963,353',\n",
       " 'Penguin',\n",
       " '72',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Rubenfeld, Jed',\n",
       " '962,515',\n",
       " 'Headline',\n",
       " '73',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Osbourne, Sharon',\n",
       " '959,496',\n",
       " 'Little, Brown Book',\n",
       " '74',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Coelho, Paulo',\n",
       " '956,114',\n",
       " 'HarperCollins',\n",
       " '75',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " \"O'Grady, Paul\",\n",
       " '945,640',\n",
       " 'Transworld',\n",
       " '76',\n",
       " 'Notes from a Small Island',\n",
       " 'Bryson, Bill',\n",
       " '931,312',\n",
       " 'Transworld',\n",
       " '77',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Oliver, Jamie',\n",
       " '925,425',\n",
       " 'Penguin',\n",
       " '78',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'Fielding, Helen',\n",
       " '924,695',\n",
       " 'Pan Macmillan',\n",
       " '79',\n",
       " \"Jamie's Italy\",\n",
       " 'Oliver, Jamie',\n",
       " '906,968',\n",
       " 'Penguin',\n",
       " '80',\n",
       " 'I Can Make You Thin',\n",
       " 'McKenna, Paul',\n",
       " '905,086',\n",
       " 'Transworld',\n",
       " '81',\n",
       " 'Down Under',\n",
       " 'Bryson, Bill',\n",
       " '890,847',\n",
       " 'Transworld',\n",
       " '82',\n",
       " 'Summons,The',\n",
       " 'Grisham, John',\n",
       " '869,671',\n",
       " 'Random House',\n",
       " '83',\n",
       " 'Small Island',\n",
       " 'Levy, Andrea',\n",
       " '869,659',\n",
       " 'Headline',\n",
       " '84',\n",
       " 'Nigella Express',\n",
       " 'Lawson, Nigella',\n",
       " '862,602',\n",
       " 'Random House',\n",
       " '85',\n",
       " 'Brick Lane',\n",
       " 'Ali, Monica',\n",
       " '856,540',\n",
       " 'Transworld',\n",
       " '86',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Edwards, Kim',\n",
       " '845,858',\n",
       " 'Penguin',\n",
       " '87',\n",
       " 'Room on the Broom',\n",
       " 'Donaldson, Julia',\n",
       " '842,535',\n",
       " 'Pan Macmillan',\n",
       " '88',\n",
       " 'About a Boy',\n",
       " 'Hornby, Nick',\n",
       " '828,215',\n",
       " 'Penguin',\n",
       " '89',\n",
       " 'My Booky Wook',\n",
       " 'Brand, Russell',\n",
       " '820,563',\n",
       " 'Hodder & Stoughton',\n",
       " '90',\n",
       " 'God Delusion,The',\n",
       " 'Dawkins, Richard',\n",
       " '816,907',\n",
       " 'Transworld',\n",
       " '91',\n",
       " '\"Beano\" Annual,The',\n",
       " '0',\n",
       " '816,585',\n",
       " 'D.C. Thomson',\n",
       " '92',\n",
       " 'White Teeth',\n",
       " 'Smith, Zadie',\n",
       " '815,586',\n",
       " 'Penguin',\n",
       " '93',\n",
       " 'House at Riverton,The',\n",
       " 'Morton, Kate',\n",
       " '814,370',\n",
       " 'Pan Macmillan',\n",
       " '94',\n",
       " 'Book Thief,The',\n",
       " 'Zusak, Markus',\n",
       " '809,641',\n",
       " 'Transworld',\n",
       " '95',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Binchy, Maeve',\n",
       " '808,900',\n",
       " 'Orion',\n",
       " '96',\n",
       " 'Ghost,The',\n",
       " 'Harris, Robert',\n",
       " '807,311',\n",
       " 'Random House',\n",
       " '97',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Oliver, Jamie',\n",
       " '794,201',\n",
       " 'Penguin',\n",
       " '98',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " 'Collins, Suzanne',\n",
       " '792,187',\n",
       " 'Scholastic Ltd.',\n",
       " '99',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " 'Pelzer, Dave',\n",
       " '791,507',\n",
       " 'Orion',\n",
       " '100',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\",\n",
       " 'Oliver, Jamie',\n",
       " '791,095',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2c005c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = detail[0:500:5]\n",
    "book_name = detail[1:500:5]\n",
    "author_name=detail[2:500:5]\n",
    "vol_sales=detail[3:500:5]\n",
    "publisher = detail[4:500:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "692e4396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag =driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "len(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "075ec7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Book Name       Author Name  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame\n",
    "df = pd.DataFrame({'Rank':rank,'Book Name':book_name,'Author Name':author_name,'Volume Sales':vol_sales,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "802348c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9511e",
   "metadata": {},
   "source": [
    "# Question 9.\n",
    "Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "589df391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d4216a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://www.imdb.com/list/ls095964455/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d619305a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1407c4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = []\n",
    "year_tag = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year_tag:\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b0b1b21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "rating_tag = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]')\n",
    "for i in rating_tag:\n",
    "    rating.append(i.text.split('\\n')[0])\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e7bd0441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = []\n",
    "run_tag = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in run_tag:\n",
    "    run.append(i.text)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "377da414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d7e8a648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,091,231',\n",
       " '1,180,712',\n",
       " '989,594',\n",
       " '292,983',\n",
       " '252,155',\n",
       " '303,039',\n",
       " '145,560',\n",
       " '309,089',\n",
       " '346,420',\n",
       " '432,066',\n",
       " '476,305',\n",
       " '807,516',\n",
       " '546,026',\n",
       " '924,709',\n",
       " '531,972',\n",
       " '168,089',\n",
       " '322,421',\n",
       " '319,829',\n",
       " '1,874,123',\n",
       " '324,633',\n",
       " '445,903',\n",
       " '535,553',\n",
       " '152,339',\n",
       " '149,021',\n",
       " '407,605',\n",
       " '225,514',\n",
       " '422,180',\n",
       " '440,981',\n",
       " '993,345',\n",
       " '683,398',\n",
       " '411,040',\n",
       " '387,872',\n",
       " '136,672',\n",
       " '124,458',\n",
       " '175,543',\n",
       " '155,047',\n",
       " '230,998',\n",
       " '505,174',\n",
       " '215,242',\n",
       " '430,854',\n",
       " '520,115',\n",
       " '64,145',\n",
       " '191,030',\n",
       " '504,762',\n",
       " '385,793',\n",
       " '79,755',\n",
       " '280,819',\n",
       " '243,511',\n",
       " '225,172',\n",
       " '217,701',\n",
       " '240,748',\n",
       " '725,593',\n",
       " '130,494',\n",
       " '340,134',\n",
       " '249,889',\n",
       " '553,651',\n",
       " '546,936',\n",
       " '465,082',\n",
       " '61,281',\n",
       " '111,567',\n",
       " '342,124',\n",
       " '74,420',\n",
       " '105,269',\n",
       " '237,333',\n",
       " '95,875',\n",
       " '95,623',\n",
       " '51,191',\n",
       " '149,030',\n",
       " '369,724',\n",
       " '316,379',\n",
       " '107,059',\n",
       " '248,410',\n",
       " '570,674',\n",
       " '105,499',\n",
       " '129,652',\n",
       " '526,021',\n",
       " '108,765',\n",
       " '236,684',\n",
       " '89,513',\n",
       " '22,893',\n",
       " '144,495',\n",
       " '160,839',\n",
       " '131,788',\n",
       " '37,617',\n",
       " '288,914',\n",
       " '120,509',\n",
       " '131,883',\n",
       " '74,363',\n",
       " '108,528',\n",
       " '199,709',\n",
       " '29,141',\n",
       " '185,802',\n",
       " '217,212',\n",
       " '749,167',\n",
       " '68,730',\n",
       " '50,207',\n",
       " '61,517',\n",
       " '198,519',\n",
       " '41,591',\n",
       " '245,422']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = []\n",
    "votes_tag = driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in votes_tag:\n",
    "    votes.append(i.text)\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bce35db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,091,231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,180,712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>989,594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>292,983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,091,231  \n",
       "1    51 min     8.7  1,180,712  \n",
       "2    44 min     8.1    989,594  \n",
       "3    60 min     7.5    292,983  \n",
       "4    43 min     7.6    252,155  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,207  \n",
       "96   50 min     7.8     61,517  \n",
       "97   42 min     8.1    198,519  \n",
       "98   45 min     7.1     41,591  \n",
       "99  572 min     8.6    245,422  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "df= pd.DataFrame({'Name':detail,'Year span':year,'Genre':genre,'Run time':run,'Ratings':rating,'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6e74f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7577f",
   "metadata": {},
   "source": [
    "# Question 10.\n",
    "Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c2f7a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's connect to the webdriver\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Arpita\\Documents\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7556951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(' https://archive.ics.uci.edu/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "631d44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8684eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail=[]\n",
    "detail_tag = driver.find_elements(By.XPATH,'//p[@class=\"normal\"]')\n",
    "for i in detail_tag[8:4364]:\n",
    "    detail.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "27fb0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = detail[0:4364:7]\n",
    "datatype = detail[1:4364:7]\n",
    "task=detail[2:4364:7]\n",
    "attribute_type=detail[3:4364:7]\n",
    "instances = detail[4:4364:7]\n",
    "attributes = detail[5:4364:7]\n",
    "year=detail[6:4364:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ae4e408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623 623 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(datatype),len(task),len(attribute_type),len(instances),len(attributes),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "da442074",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [274]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataset Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatatype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttribute Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mattribute_type\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInstances\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttributes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43myear\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Dataset Name':name,'Datatype':datatype,'Task':task,'Attribute Type':attribute_type,'Instances':instances,'Attributes':attributes,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
